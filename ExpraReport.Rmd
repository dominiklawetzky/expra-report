---
title             : "Reducing Stress by Enhancing Group Identification"
shorttitle        : "Expra-Report"

author: 
  - name          : "Dominik Lawetzky"
    affiliation   : "1"
    corresponding : yes   
    email         : "d.lawetzky@stud.uni-frankfurt.de"
affiliation:
  - id            : "1"
    institution   : "Goethe University Frankfurt"
    
authornote: |
  Test

abstract: |
    Workplace-related stress impairs individual health and imposes a tale burden on health care systems. It is thus of great interest to find effective interventions for reducing workplace-related stress. Building on the Social Identity Theory, we hypothesized that both group identification and group-specific achievement norms interactively affect the amount of stress induced by a counting task. In an experimental study with (mostly) psychology students, we manipulated group identification and achievement norm and measured the amount of perceived stress after taking part in a counting task. Although we did not find the hypothesized interaction effects, raising the achievement norm resulted in a more stressful experience for the participants. Since our sampling frame is restricted and our experimental design has limitations, we recommend further research and outline an improved experimental design. Moreover, we ran a simulation for statistical power to quantify the impact of different criteria for outlier exclusion, underlining methodological considerations. In conclusion, the Social Identity Theory introduced a useful framework for understanding organizational dynamics and possibly developing interventions for reducing workplace-related stress.

bibliography      : ["citations.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : yes
figsintext        : yes
toc               : yes

appendix:
  - "appendix1.Rmd"

documentclass     : "apa6"
classoption       : "man"
output: papaja::apa6_pdf

---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(DiagrammeR)
library(ggplot2)
library(ggstatsplot)
library(car)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ez)
library(papaja)
library(cowplot)
library(Superpower)
library(psych)

## DATEN IMPORTIEREN
load("Data/merged_data.rda")


## FUNKTIONEN

outlier_sd <- function(var, sd_diff = 2, drop = F, NA.replace = F, plot = F) {
  cutoff_low <- mean(var) - sd(var) * sd_diff
  cutoff_high <- mean(var) + sd(var) * sd_diff
  outliers <- which(var < cutoff_low | var > cutoff_high)
  values <- var[outliers]
  output <- data.frame(Position = outliers, Value = values)
  
  x <- as.numeric(var)
  data <- data.frame(x)
  name <- deparse(substitute(var))
  
  if(drop == T) {
    
    if(NA.replace == F) {
      var <- var[-outliers]
    }
    else {
      var[outliers] <- NA
    }
    
  }
  else {
    var <- paste("Use 'drop = T' to get the variable without outliers SD >", sd_diff)
    print(output)
  }
  
  
  if(drop == F && NA.replace == T) {
    print("You must set 'drop = T' in order to replace outliers with 'NA'.")
  }
  
  if(plot == T) {
    p <- ggplot(data = data, aes(x = x), environment = environment()) +
      stat_bin(binwidth = .05, col = "black", fill = "black") +
      geom_vline(xintercept = cutoff_low, 
                 color = "red", 
                 linetype = "dashed") +
      geom_vline(xintercept = cutoff_high, 
                 color = "red", 
                 linetype = "dashed") +
      geom_text(aes(x = cutoff_low,
                    y = 13,
                    label = "Cutoff",
                    hjust = -.225,
                    vjust = 0,
                    angle = 0,
                    fontface = 1), 
                color = "red",
                size = 4) +
      geom_text(aes(x = cutoff_high,
                    y = 13,
                    label = "Cutoff",
                    hjust = 1.3,
                    vjust = 0,
                    angle = 0,
                    fontface = 1), 
                color = "red",
                size = 4) +
      labs(title = paste("Outlier analysis for", name), 
           subtitle = paste("SD >", sd_diff),
           x = "value",
           y = "absolute frequency") +
      theme_light() +
      theme(axis.text.x=element_text(size=rel(.75), 
                                     angle=90, 
                                     margin = margin(b = 12))) +
      theme(plot.title = element_text(size = 18, 
                                      face = "bold"))
    
    print(p)
    }
  
  return(var)
  
}

##### Umkodierung ----

# UMKODIEREN
# Umkodierung von c_0002 in zwei Variablen (1 pro Bedingung)
Merged_Data$c_0002
Merged_Data$Soc_Id <- ifelse(Merged_Data$c_0002 %in% c(1, 3), "high", "low") # Social Identity
Merged_Data$Soc_Norm <- ifelse(Merged_Data$c_0002 %in% c(1, 2), "average", "very high") # Social Norm
head(Merged_Data)

# SKALENBILDUNG
Merged_Data$AV_WHO <- rowMeans(Merged_Data[ , c(53,54,55,56,57)]) # Mittelwertbildung der genannten Spalten
Merged_Data$AV_WHO

# REKODIERUNG VON INVERTIERTEN ITEMS
Merged_Data$AV_s_1_r <- -1 * (Merged_Data$AV_s_1 - 6) # fünfstufiges Item umkodieren (je nach Anzahl der Ausprägungen die "-6" anpassen)

# DATENSATZ SORTIEREN
Selected_Data <- subset(Merged_Data, select = c("Age", "Sex", "Soc_Id", "Soc_Norm", "AV_s_1", "AV_s_2", "AV_s_3", 
                                                "AV_s_4", "AV_s_5", "AV_s_6", "AV_s_7", NULL, NULL, NULL,
                                                "v_7", "v_8", "v_9", "v_10", "v_11", "v_22"))

# UMKORDIEREN INVERTIERTER ITEMS
# Invertiert sind u. a.: s4, s5, s7, s8

Selected_Data$AV_s_2 <- -1 * (Selected_Data$AV_s_2 - 6)
Selected_Data$AV_s_3 <- -1 * (Selected_Data$AV_s_3 - 6)
Selected_Data$AV_s_4 <- -1 * (Selected_Data$AV_s_4 - 6)
Selected_Data$AV_s_5 <- -1 * (Selected_Data$AV_s_5 - 6)

Merged_Data$AV

Selected_Data <- as.data.frame(Selected_Data)

Selected_Data$stress_level <- rowMeans(Selected_Data[, 5:11]) # Stress-Skala bilden

Selected_Data$identification <- rowMeans(Selected_Data[, 12:16]) # Social-ID-Manipulation-Skala bilden

Selected_Data$Sex <- factor(Selected_Data$Sex,
                            levels = 1:3,
                            labels = c("männlich", "weiblich", "divers"))

```

\newpage

## Introduction


<!-- What are Social Norms and how do they influence behavior? -->

With their 1979 paper on "An integrative theory of intergroup conflict", Henri Tajfel and John Turner revolutionized the conception of identity in the field of Social Psychology [@tajfelIntegrativeTheoryIntergroup2001]. They revised the conception of identity by expanding it beyond the Personal Identity, including group memberships. Besides biological dispositions, individual traits, and past experiences, their theory claims that our identity consists of the groups we *identify* with. @tajfelIntegrativeTheoryIntergroup2001 termed this *social identity*. They further theorized that our social identity is not only descriptive of our group memberships but has a *normative* effect on a behavioral level.

For example, being a student means being part of the group of students in general and students studying on the same faculty, in particular. This group membership is embraced in one's identity as one see themselves as a member of this group, leading to behavioral changes based on social norms established in that group. As a student, one has to behave as such, e. g. attending courses, reading literature, and going to parties. Thus, one's social identity gradually bleeds into one's personal identity --- or is merely indistinguishable from it. 

<!-- COVID-19 pandemic as an example -->

Recently, the Social Identity Theory gained renewed attraction since it could be the foundation of strategies prompting large-scale behavioral change during the COVID-19 pandemic [see @abramsIntergroupIntragroupDimensions2021; @nevilleSocialNormsSocial2021]. @nevilleSocialNormsSocial2021 emphasized the idea of achieving maximum compliance with pandemic measurements by framing it as beneficial for one's social group, thereby making it a group norm.

<!-- Turnover Intentions as an example -->

Over the past few years, researchers have collected a magnitude of findings supporting the Social Identity approach:

- Employees who strongly identify with their workplace, therefore embracing it into their social identity, are less likely to quit. @vandickShouldStayShould2004 showed that organizational identification, mediated by job satisfaction, can explain 24% to 69% of the variance in turnover intentions.

- The identification with one's alma mater correlates with the willingness to support the university financially [@maelAlumniTheirAlma1992]. Organizational identification is associated with several factors, e. g. organizational tenure, recency of group membership, overall satisfaction with the organization, and organizational prestige.

<!-- Bomb Disposal Study as example -->

- @haslamTakingStrainSocial2005 compared military bomb disposal officers with bar workers regarding their social identification, social support, work stress, and job satisfaction. Conducting a path analysis, they conclude that organizational identification is highly correlated with decreased work stress as well as increased job satisfaction --- both for bomb disposal officers and bar workers. They argue that social identification can serve as a "buffer against the adverse effects of stress" [@haslamTakingStrainSocial2005, p. 11].


These findings attest to the core principles of @tajfelIntegrativeTheoryIntergroup2001 and demonstrate the practicality of their theory: Employers aiming at reducing turnover rates should provide team-building exercises and encourage collaborative projects. Organizations looking for donators can establish mentor programs or reach out as early as possible to former students. Workers can reduce work-related stress by reflecting on their role within their work group, thereby increasing group salience.

Building on that last intervention, we wanted to investigate if it is sufficient enough to manipulate group salience by priming on the in-group in order to reduce the amount of perceived stress during and after a counting task Additionally, we manipulated the achievement norm of the groups hypothesizing an interaction effect between group identification and achievement norm on the perceived amount of stress.

<!-- Role of Appraisal (Lazarus Stress model) -->

@lazarusStressAppraisalCoping1999 theorized that stress is the result of two stages of appraisal. The first stage raises the question of whether there *is* a problem. This alone, according to Lazarus, is not sufficient enough to evoke stress since most everyday problems are easily solvable [@folkmanStressAppraisalCoping2013]. Therefore, the secondary appraisal is whether one can *deal* with the problem. That is where social identity comes into play since it expands the scope within one has to solve the problem. Secondary appraisal is the "lens through which threat to self is appraised" [@haslamTakingStrainSocial2005, p. 9]. This leads us to the question: *How easy can we swap the optics of the lens?* 

<!-- Why is this significant -->

Answering this question could allow us to develop effective interventions for reducing work-related stress.  Reducing stress can increase overall health and psychological well-being by substantial margins [@schneidermanStressHealthPsychological2005]. On a public health level, stress-induced syndromes, especially burnout, pose a massive burden to our health care system and cost billions of dollars per year.


## Methods

<!-- General notes: Preregistration, Experimental Design developed by Rolf van Dick -->

The experimental design was preregistered to our scientific adviser Professor Dr. Rolf van Dick on November 16th 2021 (see Appendix \ref{prereg}). The preregistration was based on questions from aspredicted.org. The collection of data started two weeks later. Students from the Psychology Department who participated in the study were rewarded course credits. In order to accredit the participation, the students were given numeric pseudonyms. We had no access to these pseudonyms and were not involved in their generation as this was handled by a research assistant of the department. Since we could not collect enough data in time, Professor Dr. van Dick provided data from an earlier trial using the same experimental design. We controlled for systematic bias by randomizing the order of the rows. For the preregistration, we conducted a power analysis ($\alpha = .05$, $1-\beta \geq .8$, $f_{\text{Cohen}} = \frac{d}{2} = 0.175$) with a tool by @faulPowerFlexibleStatistical2007. Thus, we decided to aim for a sample size greater than 59 participants (see Appendix \ref{fig:power-analysis}). 

### Experimental Design

<!-- Name Independent Variable and Dependent Variable -->


<!-- Explain the operationalization of the variables -->


<!-- Explain the circumstances -->

The data collected was part of an extensive battery of questionnaires and tests. Since researchers independent of this study were interested in longitudinal effects and aimed at controlling for specific factors, the data gathering consisted of two phases (at-home trial and laboratory trial) of which this study only used the latter. Therefore, we abstain from describing the design of the at-home trial.

The participants were invited to the Psychology Department. We told them that they were assigned to a group whose members were distributed across different rooms. In fact, there were no other participants. However, we regularly let participants wait "until the other group is ready", enhancing the deception. 

In order to manipulate social identity, the participants were randomly assigned into two conditions. One group was told they were assigned to a group of individuals "very similar" to each other, sharing values and having similar attitudes towards health. They were told that they "have many things in common". The other group was told that, based on answers from the at-home trial, the members of their group were "very different", sharing different values and having diverging attitudes towards health. Overall, they were instructed that there are "many differences between them". We tested social identification using a slightly modified version of the Perceived Intragroup Variability scale by @doosjePerceivedIntragroupVariability1995a.

The trial consisted of four phases: In the first phase, we measured social identification by using the Perceived Intragroup Variability scale by @doosjePerceivedIntragroupVariability1995a. Subsequently, the participants were told that they should participate in a counting task. We manipulated the achievement norm of the group, further splitting the groups into four overall conditions in a 2 x 2 factorial design. We set the group norm to either 60 / 100 points (average achievement norm) or 90 / 100 points (high achievement norm). Aiming at testing the effect of the manipulation, we asked the participants for an estimation of how good their group will perform compared "to other groups". In the following counting task, the participants should subtract 7 from a random number as often as possible within two minutes [@haymanTWOMINUTECLINICAL1942]. The task aimed at being hard enough to induce stress as well as being accessible to a broad population. In the last phase, we used a modified version of the Perceived Stress Scale [@cohenGlobalMeasurePerceived1983] measuring the amount of stress the participants experienced during the trial. The PSS was modified in order to measure the amount of stress the counting task induced. After the experiment, the participants were thanked and fully debriefed. We appended the test battery to this manuscript (see Appendix \ref{tests}).

### Statistical Analysis

The statistical analysis was conducted in *R* (version 4.1.0) using *RStudio*. For data preparation and descriptive analysis, we used the `car`-Package by @car, `dplyr`-Package by @dplyr, `psych`-Package by @psych, and the `ggplot2`-Package by @ggplot2. In order to detect and exclude outliers, we applied the self-written function `outlier_sd()` and set the criterion to $\bar{x}_i - 2 \hat{\sigma}_i < x_i < \bar{x}_i + 2 \hat{\sigma}_i$. We conducted a two-way ANOVA (Analysis of variances), setting the tolerated $\alpha$ error to $.05$, with the `ez`-Package by @ez and utilized post-hoc tests with the `ggstatsplot`-Package by @ggstatsplot.
Moreover, the `effectsize`-Package by @effectsize was used to calculate $f_{\text{Cohen}}$ and the `Superpower` package by @superpower to run simulations. For full transparency and to increase reproducibility, we provide the *RMarkdown* script on GitHub.[^1]

[^1]: github.com


## Results

### Descriptive Statistics

Our sample consisted of 134 participants ($N = 134$) with a mean age of 22.5 ($M = 22.5$, $SD = 5.3$). $72.39 \%$ of the participants identified as female, $26.87 \%$ as male and less than $1 \%$ as non-binary (one participant). Since no gender specific hypothesis were formulated, we did not see the need to exclude the non-binary participant.

### Manipulation Check

<!-- Manipulation Check -->

We conducted a manipulation check testing for differences in mean. The group identification manipulation was successful (see Figure \ref{fig:manipulation1}), resulting in a just-about-significant difference in mean for the groups ($F_{(1, 131)} = 4.05$, $p = .046$). However, the effect size can be considered small to medium with $f_{\text{Cohen}} = 0.18$ ($90\% ~ CI ~[0.02, 0.32]$) [@cohenStatisticalPowerAnalysis2013]. The manipulation check for the achievement norm was not successful ($M_{\text{low}} = 3.16$, $SD_{\text{low}} = 0.6$, $M_{\text{high}} = 3.18$, $SD_{\text{low}} = 0.5$). Since the achievement norm was operationalized by a single item, the assumption of a metric scale necessary for a $t$-test or ANOVA was not met. Using a one-sided Wilcoxon test, we found a significant rank difference between the groups ($W = 1800$, $p = .009$, see Figure \ref{fig:manipulation1}). We want to emphasize that this non-parametric test is not fit for testing on a 4-point ordinal scale either.

``` {r prep_manipulation1, include = FALSE}

manipulation <- subset(Selected_Data, select = c("identification", "Soc_Id")) %>% data.frame()

manipulation$ID <- 1:nrow(manipulation)

manipulation$identification

# ANFORDERUNGEN FÜR ANOVA

# 1) Skalenniveaus stimmen (kategorial-/intervallskaliert)

# 2) Unabhängigkeit der Variablen ist gegeben (randomisierte Gruppenzuweisung)

# 3) Residuen sind NICHT (!) normalverteilt (deskriptiv überprüft), es gilt der zentrale Grenzwertsatz, da n > 30

# qqPlot(manipulation$identification)
# shapiro.test(manipulation$identification)

# 4) Homoskedastizität ist gegeben (Levene-Test)

# leveneTest(manipulation$identification ~ manipulation$Soc_Id)

# 5) Ausreißer erkannt und entfernt (x > 2 SD)

manipulation$identification_clean <- outlier_sd(var = manipulation$identification, 
                                                sd_diff = 2, drop = T, NA.replace = T)
manipulation <- na.omit(manipulation)


```


``` {r prep_manipulation2, include = FALSE}

# PREPARATION

achievement <- subset(Selected_Data, select = c("v_22", "Soc_Norm")) %>% data.frame()
achievement$ID <- 1:nrow(achievement)
colnames(achievement) <- c("Manipulation_Check", "Soc_Norm", "ID")
achievement$Soc_Norm <- as.factor(achievement$Soc_Norm)


# ANFORDERUNGEN FÜR WILCOXON

# 1) Skalenniveaus stimmt NICHT (ordinalskaliert)

# 2) Unabhängigkeit der Variablen ist gegeben (randomisierte Gruppenzuweisung)

# 3) Residuen sind NICHT (!) normalverteilt (deskriptiv überprüft)

qqPlot(achievement$Manipulation_Check)
shapiro.test(achievement$Manipulation_Check)

# 4) Homoskedastizität ist gegeben (Levene-Test)

leveneTest(achievement$Manipulation_Check ~ achievement$Soc_Norm)

# 5) Ausreißer werden NICHT entfernt

sd(achievement$Manipulation_Check)


# WILCOXON-TEST

levels(achievement$Soc_Norm)

wilcox.test(achievement$Manipulation_Check ~ achievement$Soc_Norm,
            paired = FALSE,
            correct = TRUE,
            alternative = "less")

```

(ref:manipulation1) (A) Manipulation check for group identification with one-way ANOVA, (B) Manipulation check for for achievement norm with Wilcoxon test.

```{r manipulation1, echo = FALSE, fig.cap = "(ref:manipulation1)", dev = "pdf", out.width = "80%", fig.align = "center", warning = FALSE, label = "manipulation1"}

manipulation_anova_plot_alt <- ggbetweenstats(data = manipulation,
                                              x = Soc_Id,
                                              y = identification_clean,
                                              type = "parametric", # ANOVA or Kruskal-Wallis
                                              var.equal = TRUE, # ANOVA or Welch ANOVA
                                              plot.type = "boxviolin",
                                              pairwise.comparisons = TRUE,
                                              pairwise.display = "significant",
                                              effsize.type = "omega",
                                              centrality.plotting = TRUE,
                                              bf.message = FALSE,
                                              k = 2,
                                              conf.level = .95,
                                              results.subtitle = TRUE,
                                              outlier.tagging = FALSE) +
                                labs(x = "Group Identification Condition",
                                     y = "Group Identification Check") +
                                scale_color_manual(values = c("#5EB1BF", "#FF595E"))


boxplot <- ggplot(achievement, aes(x = Soc_Norm, y = Manipulation_Check, color = Soc_Norm)) + 
              geom_boxplot(outlier.colour = "#5EB1BF",
                           outlier.shape = 8, outlier.size = 4) +
              stat_summary(fun = mean, geom  ="point", shape = 23, size = 4) +
              labs(x = "Achievement Norm Condition",
                   y = "Achievement Norm Check") +
              theme_ggstatsplot() +
              guides(color = "none") +
              ylim(1, 4) +
              scale_color_manual(values = c("#5EB1BF", "#FF595E"))

cowplot::plot_grid(manipulation_anova_plot_alt, boxplot, labels = c("A", "B"), rel_widths = c(1.5, 1))


```

### Hypothesis Testing


<!-- Assumption -->

Prior to the hypothesis testing, we checked all necessary statistical assumptions for an ANOVA and found no violations. The Levene test for homoscedasticity initially resulted in a just-above-significant $p$-value ($F_{(3, 130)} = 2.43$, $p = .068$). Although after excluding four outliers that fell outside the criterion of $\pm 2 \hat{\sigma}_i$, the Levene test was clearly non-significant ($F_{(3, 126)} = 1.78$, $p = .154$). Normality was assumed by inspecting a Q-Q-plot (see Figure \ref{fig:qqplotanova}). We tested our hypothesis by conducting a two-way ANOVA. Therewith we could not find any significant differences in the perceived amount of stress relative to group identification ($F_{(1, 126)} = 0.34$, $p = .561$), but found a highly significant difference relative to achievement norm ($F_{(1, 126)} = 8.41$, $p = .004$, see Figure \ref{fig:anova-1}). According to @cohenStatisticalPowerAnalysis2013, the effect size of this main effect is considered medium size ($f_{\text{Cohen}} = 0.26$, $90\% ~ CI ~ [0.11, 0.41]$, see Table \ref{tab:anova-table}). We can not report any significant interaction ($F_{(1, 126)} = 2.65$, $p = .106$, see Figure \ref{fig:interaction}). For further exploration, we conducted a post-hoc $t$-test with Holm-Bonferroni correction and found a significant difference between participants with high group identification as well as an *average* achievement norm and participants with high group identification as well as an *very high* achievement norm (see Figure \ref{fig:anova-1}), indicating that raising the achievement norm increases stress independent of group identification.

<!-- ANOVA results -->

``` {r prep_anova, include = FALSE}

anova_data <- subset(Selected_Data, select = c(stress_level, Soc_Id, Soc_Norm))
anova_data$ID <- 1:nrow(anova_data)
anova_data <- anova_data %>% unite(condition, Soc_Id, Soc_Norm, sep = " / ", remove = F)

anova_data$stress_level <- outlier_sd(var = anova_data$stress_level, sd_diff = 2, drop = T, NA.replace = T, plot = F)
anova_data <- na.omit(anova_data)

```

(ref:anova-1) Pairwise comparison for two-way ANOVA.

```{r anova-1, echo = FALSE, fig.cap = "(ref:anova-1)", dev = "pdf", out.width = "90%", fig.align = "center", warning = FALSE, label = "anova-1"}
ggbetweenstats(data = anova_data,
               x = condition,
               y = stress_level,
               type = "parametric", # ANOVA or Kruskal-Wallis
               var.equal = TRUE, # ANOVA or Welch ANOVA
               plot.type = "boxviolin",
               pairwise.comparisons = TRUE,
               pairwise.display = "all",
               p.adjust.method = "holm",
               effsize.type = "omega",
               centrality.plotting = TRUE,
               bf.message = FALSE,
               k = 2,
               conf.level = .95,
               results.subtitle = TRUE,
               sample.size.label = TRUE,
               ggsignif.args = list(textsize = 2.5, margin_top = 0.10, tip_length = 0.03,
                                    step_increase = 0.06)) +
               labs(#title = "ANOVA: Stress-Level relativ zu Salienz der \nsozialen Gruppe und Achievement Norm", 
                     #subtitle = paste("n =", NROW(anova_data)),
                     x = "Group Identification / Achievement Norm",
                     y = "Stress Level",
                     color = "Conditions") +
                theme_ggstatsplot() +
                theme(legend.position = "none") +
                ylim(0, 5.5) +
                scale_color_manual(values = c("#042A2B", 
                                             "#5EB1BF", 
                                             "#54F2F2", 
                                             "#FF595E"))

```


<!-- Varying the outlier criterion -->

### Exploratory Analysis and Simulations

Since our criterion for excluding outliers was quite conservative, we replicated the two-way ANOVA with values within three standard deviations ($\bar{x}_i - 3 \hat{\sigma}_i < x_i < \bar{x}_i + 3 \hat{\sigma}_i$). Adding four more previously excluded participants to our analysis, we still could not find a main effect for group identification ($F_{(1, 130)} = 0.47$, $p = .493$). However, we discovered a drastically decreased $p$-value for group identification ($F_{(1, 130)} = 12.87$, $p < .001$) and a significant interaction effect for group identification and achievement norm ($F_{(1, 130)} = 5.36$, $p = .040$). In order to quantify the impact of the different outlier exclusion criteria, we simulated a two-way ANOVA with both criteria 1.000 times using the `Superpower` package by @superpower. Liberalizing the criterion lead to an increase in power from $61.90 \%$ to $78.20 \%$ and $15.20 \%$ to $27 \%$ for the main effect of the Achievement Norm condition and the interaction effect respectively (see Appendix \ref{fig:simulation-plot1} and \ref{fig:simulation-plot2}). The differences in effect size were minor (see Table \ref{tab:simulation-table}). We will discuss the implications of this later on.

```{r simulation-prep, include = FALSE}
# 2 SD

anova_data <- subset(Selected_Data, select = c(stress_level, Soc_Id, Soc_Norm))
anova_data$ID <- 1:nrow(anova_data)
anova_data <- anova_data %>% unite(condition, Soc_Id, Soc_Norm, sep = "/", remove = F)

anova_data$stress_level <- outlier_sd(var = anova_data$stress_level, sd_diff = 2, drop = T, NA.replace = T, plot = F)
anova_data <- na.omit(anova_data)

describeBy(anova_data$stress_level, anova_data$condition)

design_result1 <- ANOVA_design(design = "2b*2b",
                              n = c(33, 27, 31, 35), 
                              mu = c(2.32, 2.67, 2.43, 2.58), 
                              sd = c(.57, .67, .67, .52), 
                              r = 0, 
                              labelnames = c("group_identification", "high", "low", 
                              "achievement_norm", "average", "very high"),
                              plot = TRUE)

nsims <- 1000

simulation1 <- ANOVA_power(design_result1,
            alpha = .05,
            nsims = nsims,
           seed = 1234,
           verbose = FALSE)


# 3 SD

anova_data <- subset(Selected_Data, select = c(stress_level, Soc_Id, Soc_Norm))
anova_data$ID <- 1:nrow(anova_data)
anova_data <- anova_data %>% unite(condition, Soc_Id, Soc_Norm, sep = "/", remove = F)

anova_data$stress_level <- outlier_sd(var = anova_data$stress_level, sd_diff = 3, drop = T, NA.replace = T, plot = F)
anova_data <- na.omit(anova_data)

describeBy(anova_data$stress_level, anova_data$condition)

design_result2 <- ANOVA_design(design = "2b*2b",
                               n = c(33, 30, 31, 35), 
                               mu = c(2.32, 2.79, 2.43, 2.58), 
                               sd = c(.57, .73, .67, .52), 
                               r = 0, 
                               labelnames = c("group_identification", "high", "low", 
                                              "achievement_norm", "average", "very high"),
                               plot = TRUE)

nsims <- 1000

 simulation2 <- ANOVA_power(design_result2,
                            alpha = .05,
                           nsims = nsims,
                           seed = 1234,
                           verbose = FALSE)
```



```{r simulation-table, echo = FALSE, dev = "pdf", out.width = "100%", fig.align = "left", warning = FALSE, label = "simulation-table"}

# Table

table <- data.frame(Condition = c("Group Identification", "Achievement Norm", "Interaction"),
                    Power2SD = simulation1$main_results[, 1],
                    EffSize2SD = round(sqrt(simulation1$main_results[, 2]), 2),
                    Power3SD = simulation2$main_results[, 1],
                    EffSize3SD = round(sqrt(simulation2$main_results[, 2]), 2))

colnames(table) <- c("Predictor", "Power ($2 SD$)", "$f_{\\text{Cohen}}$ ($2 SD$)", "Power ($3 SD$)", "$f_{\\text{Cohen}}$ ($3 SD$)")
 
apa_table(table, "Simulation of power and effect size for different outlier exclusion criterion.", booktabs = TRUE, escape = FALSE, align = c("l", "c", "c", "c", "c"))


```

\newpage

## Discussion

<!-- SUMMARY -->
We were not able to find the hypothesized main effect for group identification on the perceived amount of stress. Neither could we find an interaction effect between group identification and achievement norm. Increased group identification cannot cushion the amount of stress caused by an enhanced achievement norm. With the design we used, we were not successful in swapping the optics of the lens "through which threat to self is appraised" [@haslamTakingStrainSocial2005, p. 9]. Despite the fact that we managed to successfully manipulate group identification and the group-specific achievement norm, the consequences on the perceived amount of stress were minor.

The only factor consistently leading to significant changes in the amount of stress was the achievement norm itself, setting the standard participants could compare their performance with. The effect was strongest for participants in the high group identification condition, resulting in a significant difference in the post-hoc pairwise test. Although the post-hoc test is not adequate for testing our hypothesis, we provide two possible explanations for this observation: **(1)** Increasing group identification changes how one appraises an achievement norm. Thus, group members are more likely to perform in accordance with enhanced performance standards which leads to a more stressful experience. This explanation is not directly supported by our results since we did not measure situational motivation. **(2)** Building on the first explanation, the appraisal of an achievement norm could additionally depend on intrapersonal factors, e.g. conscientiousness or need for achievement. To corroborate this hypothesis, we would need to control for these factors and expand the sampling frame. 


<!-- CAVEATS -->
<!-- Sample: Gender specific differences regarding stress -->
The observed dominance of female participants in our sample can be ascribed to the sampling frame of mainly psychology students who are predominantly female [@msPsychologieStudiumMannerMinderheit2016]. Since the admission criteria for psychology are strict and conscientiousness is generally considered as major predictor for academic success [@kertechianConscientiousnessKeySuccess2018; @conradConscientiousnessAcademicPerformance2012], we assume that conscientiousness and need for achievement are above-average for the participants of our experiment. This assumption is consistent with our second explanation, including intrapersonal factors as mediator variable between achievement norm and stress reaction.

<!-- Outlier criteria !!! -->

Additional to the restricted sampling frame, we further restricted the variance of our data by using a conservative outlier criterion, excluding participants deviating more than two standard deviation on the dependent variable. As a general rule, excluding outliers increases the chance of rejecting the null hypothesis as ANOVA's essential $F$ statistic is a ratio of variances, and outliers tend to increase the variance disproportionately to the sample size they add to. Thus, outliers introduce "blur" into the group distributions we compare, reducing the chance to find population differences. However, this changes as several outliers in the overall sample accumulate in one group. Dropping these values reduces the statistical power as it decreases the mean sum of squares within the groups disproportionately to the mean sum of squares between the groups. In summary, if one group accounts for a disproportionate amount of overall variance and the same group differs in mean from other groups, dropping outliers based on variance (or standard deviation) changes both statistical power and effect size. As we see in Table \ref{tab:simulation-table}, liberalizing the outlier exclusion criterion leads to an increase in power for every predictor. The biggest increase was simulated for the interaction effect from our original hypothesis.

We want to emphasize that outlier exclusion has a major impact on parametric tests and should be thoroughly considered. Our simulation of power and effect sizes supports this. There are a number of statistical tests to detect outliers based on sample size and the desired confidence interval, e. g. Rosner's test [@rosnerPercentagePointsGeneralized1983]. 

<!-- Manipulation Check for Achievement Norm with a single item -->

Another caveat of our experimental design is the insufficient check for the achievement norm manipulation. We operationalized achievement norm by asking the participants to compare their group's prospective performance to other groups, providing data on a 4-point ordinal scale for the achievement norm *relative* to fictional comparisons. For such a restricted scale, parametric tests are inadequate, and non-parametric rank-sum differences are minor. We suggest using a questionaire with generally more items, resulting in quasi-interval scaled values.\footnote{We could not find a validated test for group-specific achievement norms.}

<!-- PROSPECTS -->
<!-- Priming on group identification -->
Although our study has a number of caveats and we were not able to corroborate our hypothesis, we can derive some conclusions from it. First and foremost, increasing the achievement norm can lead to a more stressful experience. We think this is especially the case for conscientious individuals with a high need for achievement. Based on our results, we suggest that intrapersonal factors mediate the effect of group identification and achievement norms on stress. This could be subject to further research. 

Reducing stress can increase overall health and psychological well-being by substantial margins [@schneidermanStressHealthPsychological2005]. @hanEstimatingAttributableCost2019 estimate the costs of physicians burning out in the United States alone at $4.6 billion. @hassardCostWorkrelatedStress2018 reviewed the scientific literature estimating the cost of work-related stress. Their conclusion underlines major methodological difficulties, calling such estimations "important conversational guesstimates". Although we cannot quantify the economic burden, no one denies that it is massive.

Therefore, establishing appropriate strategies to decrease the perceived amount of (work-related) stress could not only have enormous individual health benefits. If our theory proves true, companies could extend team-building programs in order to strengthen workplace identification. Responding to different needs, organizations could reevaluate the achievement norms they set on a per-employee basis, further decreasing work-related stress. That should consequently lead to an increase in productivity. On a public health level, even small decreases in work-related stress could scale relieving the economy of a tale burden of losses in productivity and overly high healthcare costs.









<!-- 

Chechlist:
- Cite all packages
- Cite all questionaires
- Check figure titles
- Check citations
- Include important R code in the appendix
- Include assumption test plots in appendix
- Include full questionaire in appendix
- Include Outlier Detection Function in appendix

-->

\newpage

## References




